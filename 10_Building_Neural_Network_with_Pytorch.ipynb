{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b69a880-4748-4148-bf5d-d757df4d9bbb",
   "metadata": {},
   "source": [
    "We are going to build a Resnet based Neural network to classify the CIFAR 10 Dataset. Before, we begin, let me say that the purpose of this tutorial is not to achieve the best possible accuracy on the task, but to show you how to use PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1515105-550e-408e-8bba-923358574da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815d26f-9060-4b93-b779-865439b26483",
   "metadata": {},
   "source": [
    "While PyTorch provided many layers out of the box with it's `torch.nn module`, we will have to implement the residual block ourselves. Before implementing the neural network, we implement the ResNet Block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513b6459-c4e1-45b6-884b-c1efde57ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU(inplace=True)(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU(inplace=True)(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002aa65f-7f22-4fad-93ff-f93fd6ab4736",
   "metadata": {},
   "source": [
    "Now, we can define our full network.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ae46bd-1d98-4a5c-bf32-78817e3b89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.block1 = self._create_block(64, 64, stride=1)\n",
    "        self.block2 = self._create_block(64, 128, stride=2)\n",
    "        self.block3 = self._create_block(128, 256, stride=2)\n",
    "        self.block4 = self._create_block(256, 512, stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _create_block(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, stride),\n",
    "            ResidualBlock(out_channels, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = nn.AvgPool2d(4)(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d4faa-f57a-46d2-b88c-2d3c3f2823a8",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 Dataset and Preprocess\r\n",
    "This code snippet demonstrates how to download the CIFAR-10 dataset and preprocess it for training and testing purposes using PyTorch.\r",
    "on\r\n",
    "- **CIFAR-10 Dataset**: CIFAR-10 is a popular benchmark dataset consisting of 60,000 32x32 color images in 10 classes, with 6,000 images per class. It is commonly used for image classification tasks.\r\n",
    "- **Data Preparation**:\r\n",
    "  - **Training Data**:\r\n",
    "    - Downloads the CIFAR-10 training dataset to the specified directory.\r\n",
    "    - Applies a series of transformations including resizing the images to 224x224, random horizontal and vertical flips for data augmentation, converting images to PyTorch tensors, and normalizing the pixel values.\r\n",
    "  - **Testing Data**:\r\n",
    "    - Downloads the CIFAR-10 testing dataset to the specified directory.\r\n",
    "    - Applies transformations similar to the training data, except for data augmentation.\r\n",
    "- **Transformations**:\r\n",
    "  - `Resize`: Resizes the images to a standard size of 224x224 pixels.\r\n",
    "  - `RandomHorizontalFlip` and `RandomVerticalFlip`: Randomly flips the images horizontally and vertically during training for data augmentation.\r\n",
    "  - `ToTensor`: Converts the images to PyTorch tensors.\r\n",
    "  - `Normalize`: Normalizes the pixel values of the images using pre-defined mean and standard deviation values for each channel.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdc30de-974a-47af-8d00-7c30ced5a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download CIFAR10 dataset\n",
    "data_train = torchvision.datasets.CIFAR10(\n",
    "    \"./data/cifar\", download=True, \n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(32),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomVerticalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "        \n",
    "data_test = torchvision.datasets.CIFAR10(\n",
    "    \"./data/cifar\", download=True, train=False,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(32),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98718cf4-11bd-4e50-9792-1b60d718cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab626b-fec2-4d41-b0a7-42e81635aaba",
   "metadata": {},
   "source": [
    "### Define Train and Test Dataloaders\r",
    "w\r\n",
    "The code snippet defines PyTorch dataloaders for the training and testing datasets, which are essential components for iterating over the data during training and evaluation processestion\r\n",
    "- **Train Dataloader**:\r\n",
    "  - Constructs a dataloader for the training dataset (`data_train`).\r\n",
    "  - Batch size is set to `BATCH_SIZE` (previously defined as 64).\r\n",
    "  - Utilizes a random sampler (`torch.utils.data.sampler.RandomSampler`) to shuffle the data before each epoch.\r\n",
    "  - `pin_memory` is set to `True` to optimize data transfer to CUDA-compatible devices.\r\n",
    "- **Test Dataloader**:\r\n",
    "  - Constructs a dataloader for the testing dataset (`data_test`).\r\n",
    "  - Batch size is set to `BATCH_SIZE`.\r\n",
    "  - Utilizes a sequential sampler (`torch.utils.data.sampler.SequentialSampler`) to iterate over the data in a sequential manner without shuffling.\r\n",
    "  - `pin_memory` is set to `True` for efficient data transfer during evaluation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41518e5-bd53-48ff-969b-4eb6685f74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE, sampler=torch.utils.data.sampler.RandomSampler(data_train), pin_memory=True)\n",
    "\n",
    "# Define test dataloader\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=BATCH_SIZE, sampler=torch.utils.data.sampler.SequentialSampler(data_test), pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dbd0c7-7f98-404e-aba2-ca154abba785",
   "metadata": {},
   "source": [
    "### Model Initialization and Training Setup\r",
    "w\r\n",
    "This code snippet initializes a ResNet model, sets up the training configuration including the loss function, optimizer, and learning rate schedulertion\r\n",
    "- **Model Initialization**:\r\n",
    "  - Creates an instance of the ResNet model (`clf`).\r\n",
    "  - If CUDA is available (`cuda_available`), moves the model to the GPU for accelerated computation.\r\n",
    "\r\n",
    "- **Loss Function**:\r\n",
    "  - Defines the loss function as the Cross Entropy Loss (`nn.CrossEntropyLoss()`). This loss function is commonly used for multi-class classification tasks.\r\n",
    "\r\n",
    "- **Optimizer**:\r\n",
    "  - Configures the Stochastic Gradient Descent (SGD) optimizer (`optim.SGD`) to optimize the parameters of the ResNet model.\r\n",
    "  - Learning rate is set to 0.1, momentum to 0.9, and weight decay to 5e-4.\r\n",
    "\r\n",
    "- **Learning Rate Scheduler**:\r\n",
    "  - Sets up a MultiStepLR learning rate scheduler (`torch.optim.lr_scheduler.MultiStepLR`) to adjust the learning rate during training.\r\n",
    "  - The learning rate is reduced by a factor of 0.1 at epochs 150 and 200.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d54d3d3-b932-4eed-a91e-fdc2cdd629f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ResNet()\n",
    "if cuda_available:\n",
    "    clf = clf.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(clf.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f67dc-6999-47a7-a20c-7a9ef38b8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Test Acc : 40.370\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Test Acc : 50.600\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Test Acc : 51.660\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Test Acc : 64.460\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Test Acc : 67.910\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Test Acc : 66.280\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Test Acc : 66.100\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Test Acc : 67.800\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Test Acc : 71.260\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    for inputs, targets in train_dataloader:\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = clf(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "      \n",
    "    # Evaluate\n",
    "    clf.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_dataloader:\n",
    "            if cuda_available:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = clf(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "        print('--------------------------------------------------------------')\n",
    "    clf.train()\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd96f6-b4da-497e-b1b4-2305d3fe5fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
